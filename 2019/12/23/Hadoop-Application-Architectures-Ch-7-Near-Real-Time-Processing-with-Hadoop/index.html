<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hadoop Application Architectures Ch.7 Near-Real-Time Processing with Hadoop | Ansel&#39;s Note</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Straming processing tools  Apache Storm Apache Spark Streaming Apache Samza Apache Flume via Flume interceptors Apache Flink  Not include  Kafka is only a message bus, not processing streaming data">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop Application Architectures Ch.7 Near-Real-Time Processing with Hadoop">
<meta property="og:url" content="https://weasellin.github.io/2019/12/23/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/index.html">
<meta property="og:site_name" content="Ansel&#39;s Note">
<meta property="og:description" content="Straming processing tools  Apache Storm Apache Spark Streaming Apache Samza Apache Flume via Flume interceptors Apache Flink  Not include  Kafka is only a message bus, not processing streaming data">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/storm_architecture.png">
<meta property="og:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/storm_topology.png">
<meta property="og:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_simple_count.png">
<meta property="og:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_multiple.png">
<meta property="og:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_stateful.png">
<meta property="article:published_time" content="2019-12-23T00:46:04.000Z">
<meta property="article:modified_time" content="2020-01-21T00:47:52.000Z">
<meta property="article:author" content="Ansel Lin">
<meta property="article:tag" content="reading_note">
<meta property="article:tag" content="data_engineering">
<meta property="article:tag" content="hadoop">
<meta property="article:tag" content="hadoop_application_architectures">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/storm_architecture.png">
  
    <link rel="alternative" href="/atom.xml" title="Ansel&#39;s Note" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 4.2.0"></head>
<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <section id="main"><article id="post-Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hadoop Application Architectures Ch.7 Near-Real-Time Processing with Hadoop
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2019/12/23/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/" class="article-date">
  <time datetime="2019-12-23T00:46:04.000Z" itemprop="datePublished">2019-12-23</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>Straming processing tools</p>
<ul>
<li><em>Apache Storm</em></li>
<li><em>Apache Spark Streaming</em></li>
<li><em>Apache Samza</em></li>
<li><em>Apache Flume</em> via Flume interceptors</li>
<li><em>Apache Flink</em></li>
</ul>
<p>Not include</p>
<ul>
<li><em>Kafka</em><ul>
<li>is only a message bus, not processing streaming data</li>
</ul>
</li>
<li><em>Impala, Apache Drill, or Presto</em><ul>
<li>are the low-latency, massively parallel processing (MPP) query engines</li>
</ul>
</li>
</ul>
<p>NRT, near-real-time, processing</p>
<h2 id="Stream-Processing"><a href="#Stream-Processing" class="headerlink" title="Stream Processing"></a>Stream Processing</h2><p>Common functions,</p>
<ul>
<li>Aggregation</li>
<li>Windowing averages</li>
<li>Record level enrichment</li>
<li>Record level alerting / validation</li>
<li>Persistence of transient data (storing state)</li>
<li>Support for Lambda Architectures</li>
<li>Higher-level functions (sorting, grouping, partitioning, joining)</li>
<li>Integration with HDFS / HBase</li>
</ul>
<h5 id="THE-LAMBDA-ARCHITECTURE"><a href="#THE-LAMBDA-ARCHITECTURE" class="headerlink" title="THE LAMBDA ARCHITECTURE"></a>THE LAMBDA ARCHITECTURE</h5><blockquote>
<p>The Lambda Architecture, as defined by Nathan Marz and James Warren and described more thoroughly in their book Big Data (Manning), is a general framework for scalable and fault-tolerant processing of large volumes of data.</p>
</blockquote>
<ul>
<li>Batch layer<ul>
<li>immutable copy of the master data</li>
<li>precomputes the <em>batch views</em></li>
</ul>
</li>
<li>Serving layer<ul>
<li>indexes the batch views, loads them, and makes them available for low-latency querying</li>
</ul>
</li>
<li>Speed layer<ul>
<li>is essentially the real-time layer in the architecture</li>
<li>creates views on data as it arrives in the system</li>
</ul>
</li>
</ul>
<p>Processing Flow,</p>
<ul>
<li>new data will be sent to the <strong>batch</strong> and <strong>speed</strong> layers<ul>
<li>in the batch layer, appended to the master data set</li>
<li>in the speed layer, used to do incremental updates of the real-time views</li>
</ul>
</li>
<li>at query time<ul>
<li>data from both layers will be combined</li>
<li>when the data is available in the <strong>batch</strong> and <strong>serving</strong> layers, it can be discarded from the <strong>speed</strong> layer</li>
</ul>
</li>
</ul>
<p>Advantage,</p>
<ul>
<li>fault tolerant</li>
<li>low latency</li>
<li>error correction</li>
</ul>
<h5 id="MICROBATCHING-VERSUS-STREAMING"><a href="#MICROBATCHING-VERSUS-STREAMING" class="headerlink" title="MICROBATCHING VERSUS STREAMING"></a>MICROBATCHING VERSUS STREAMING</h5><ul>
<li>processing logic simplification</li>
<li>message processing overhead (batch <em>puts</em>)</li>
<li>exactly-once</li>
<li>Storm, pure streaming tool</li>
</ul>
<h2 id="Apache-Storm"><a href="#Apache-Storm" class="headerlink" title="Apache Storm"></a>Apache Storm</h2><h3 id="Storm-High-Level-Architecture"><a href="#Storm-High-Level-Architecture" class="headerlink" title="Storm High-Level Architecture"></a>Storm High-Level Architecture</h3><p><img src="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/storm_architecture.png" alt="Storm Architecture"></p>
<h3 id="Storm-Topologies"><a href="#Storm-Topologies" class="headerlink" title="Storm Topologies"></a>Storm Topologies</h3><p><img src="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/storm_topology.png" alt="Storm Topology"></p>
<ul>
<li>In Storm you are building a topology that is solving a problem.</li>
<li>In Trident and Spark Streaming you are expressing how to solve a problem, and the topology is constructed for you behind the scenes.</li>
</ul>
<h3 id="Tuples-and-Streams"><a href="#Tuples-and-Streams" class="headerlink" title="Tuples and Streams"></a>Tuples and Streams</h3><p>A stream is an unbounded sequence of tuples between any two nodes in a topology.</p>
<h3 id="Spouts-and-Bolts"><a href="#Spouts-and-Bolts" class="headerlink" title="Spouts and Bolts"></a>Spouts and Bolts</h3><ul>
<li>Spouts<ul>
<li>provide the source of streams in a topology</li>
<li>read data from some external source, and emit one or more streams</li>
</ul>
</li>
<li>Bolts<ul>
<li>consume streams in a topology</li>
<li>do some processing on the tuples in the stream</li>
<li>then emit zero or more tuples to downstream bolts or external system as a data persistence layer</li>
</ul>
</li>
</ul>
<h3 id="Stream-Groupings"><a href="#Stream-Groupings" class="headerlink" title="Stream Groupings"></a>Stream Groupings</h3><p>An important feature of Storm, over Flume.</p>
<p>Groupings,</p>
<ul>
<li>Shuffle grouping<ul>
<li>evenly and randomly distributing tuples to each downstream bolts</li>
</ul>
</li>
<li>Fields grouping<ul>
<li>based on the specified field(s) in the tuples, send to the same bolt</li>
<li>like partitioning by hash key</li>
</ul>
</li>
<li>All grouping<ul>
<li>fan-out</li>
<li>replicates stream to all bolts</li>
</ul>
</li>
<li>Global grouping<ul>
<li>fan-in, collecting</li>
<li>sends an entire stream to a single bolt</li>
</ul>
</li>
</ul>
<h3 id="Reliability-of-Storm-Applications"><a href="#Reliability-of-Storm-Applications" class="headerlink" title="Reliability of Storm Applications"></a>Reliability of Storm Applications</h3><p>The ability to guarantee message processing relies on having a reliable message source, ex. <em>Kafka</em>.</p>
<ul>
<li>At-most-once processing</li>
<li>At-least-once processing</li>
<li>Exactly-once processing<ul>
<li>leverage an additional abstraction over core Storm, like Trident</li>
</ul>
</li>
</ul>
<h3 id="Storm-Example-Simple-Moving-Average"><a href="#Storm-Example-Simple-Moving-Average" class="headerlink" title="Storm Example: Simple Moving Average"></a>Storm Example: Simple Moving Average</h3><ul>
<li>Linked list for the windowing buffer</li>
<li><code>suffleGrouping</code> and <code>fieldGrouping(new Field(&quot;ticker&quot;))</code> in <code>buildTopology()</code></li>
</ul>
<h3 id="Evaluating-Storm"><a href="#Evaluating-Storm" class="headerlink" title="Evaluating Storm"></a>Evaluating Storm</h3><h5 id="SUPPORT-FOR-AGGREGATION-AND-WINDOWING"><a href="#SUPPORT-FOR-AGGREGATION-AND-WINDOWING" class="headerlink" title="SUPPORT FOR AGGREGATION AND WINDOWING"></a>SUPPORT FOR AGGREGATION AND WINDOWING</h5><ul>
<li>easy to implement</li>
<li>state, counters not fault-tolerant, since it uses local storage<ul>
<li>if using external storage, like HBase or Memcached, notice the sync overhead, and progress loss trade-off</li>
</ul>
</li>
</ul>
<h5 id="ENRICHMENT-AND-ALERTING"><a href="#ENRICHMENT-AND-ALERTING" class="headerlink" title="ENRICHMENT AND ALERTING"></a>ENRICHMENT AND ALERTING</h5><h5 id="LAMDBA-ARCHITECTURE"><a href="#LAMDBA-ARCHITECTURE" class="headerlink" title="LAMDBA ARCHITECTURE"></a>LAMDBA ARCHITECTURE</h5><ul>
<li>batch processes implemented with ex. MapReduce or Spark</li>
</ul>
<h2 id="Trident"><a href="#Trident" class="headerlink" title="Trident"></a>Trident</h2><ul>
<li>a higher-level abstraction over Storm</li>
<li>wrap Storm in order to provide support for transactions over Storm</li>
<li>follows a declarative programming model similar to SQL</li>
<li>use <em>operations</em> for processing, such as filters, splits, merges, joins, and groupings</li>
<li>follows a microbatching model<ul>
<li>providing a model where exactly-once semantics can be more easily supported</li>
<li>provides the ability to replay tuples in the event of failure</li>
<li>provides management of batches to ensure that tuples are processed exactly once</li>
</ul>
</li>
</ul>
<h3 id="Evaluating-Trident"><a href="#Evaluating-Trident" class="headerlink" title="Evaluating Trident"></a>Evaluating Trident</h3><h5 id="SUPPORT-FOR-AGGREGATION-AND-WINDOWING-1"><a href="#SUPPORT-FOR-AGGREGATION-AND-WINDOWING-1" class="headerlink" title="SUPPORT FOR AGGREGATION AND WINDOWING"></a>SUPPORT FOR AGGREGATION AND WINDOWING</h5><ul>
<li>now can persist to external storage systems to maintain state with higher throughput</li>
</ul>
<h5 id="ENRICHMENT-AND-ALERTING-1"><a href="#ENRICHMENT-AND-ALERTING-1" class="headerlink" title="ENRICHMENT AND ALERTING"></a>ENRICHMENT AND ALERTING</h5><ul>
<li>the batches are merely wrappers, nothing more than a marker at the end of a group of tuples</li>
</ul>
<h5 id="LAMDBA-ARCHITECTURE-1"><a href="#LAMDBA-ARCHITECTURE-1" class="headerlink" title="LAMDBA ARCHITECTURE"></a>LAMDBA ARCHITECTURE</h5><ul>
<li>still need to implement the batch process in something like MapReduce or Spark</li>
</ul>
<h2 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h2><ul>
<li>Reliable persistence of intermediate data for your counting and rolling averages.</li>
<li>Supported integration with external storage systems like HBase.</li>
<li>Reusable code between streaming and batch processing.</li>
<li>The Spark Streaming microbatch model allows for processing patterns that help to mitigate the risk of duplicate events.</li>
</ul>
<p>Concept:</p>
<ul>
<li>normal <em>RDD</em>: a reference to a distributed immutable collection</li>
<li><em>DStream</em>: a reference to a distributed immutable collection in relation to a batch window, chunk</li>
</ul>
<p><img src="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_simple_count.png" alt="Spark Streaming simple count example"></p>
<p><img src="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_multiple.png" alt="Spark Streaming multiple stream"></p>
<p><img src="https://github.com/weasellin/docker-hexo/raw/master/source/_posts/Hadoop-Application-Architectures-Ch-7-Near-Real-Time-Processing-with-Hadoop/spark_stream_stateful.png" alt="Maintaining state in Spark Streaming"></p>
<ul>
<li><code>updateStateByKey()</code></li>
<li><em>checkpoint</em></li>
</ul>
<h5 id="DSTREAMS-PROVIDES-FAULT-TOLERANCE"><a href="#DSTREAMS-PROVIDES-FAULT-TOLERANCE" class="headerlink" title="DSTREAMS PROVIDES FAULT TOLERANCE"></a>DSTREAMS PROVIDES FAULT TOLERANCE</h5><ul>
<li>saved state to <em>checkpoint</em> directory every <em>N</em> microbatch</li>
<li>recreate from cache in memory or disk</li>
</ul>
<h5 id="SPARK-STREAMING-FAULT-TOLERANCE"><a href="#SPARK-STREAMING-FAULT-TOLERANCE" class="headerlink" title="SPARK STREAMING FAULT TOLERANCE"></a>SPARK STREAMING FAULT TOLERANCE</h5><ul>
<li>WAL for driver process failure recovery</li>
<li>resilient RDD, configurable</li>
</ul>
<h3 id="Evaluating-Spark-Streaming"><a href="#Evaluating-Spark-Streaming" class="headerlink" title="Evaluating Spark Streaming"></a>Evaluating Spark Streaming</h3><h5 id="SUPPORT-FOR-AGGREGATION-AND-WINDOWING-2"><a href="#SUPPORT-FOR-AGGREGATION-AND-WINDOWING-2" class="headerlink" title="SUPPORT FOR AGGREGATION AND WINDOWING"></a>SUPPORT FOR AGGREGATION AND WINDOWING</h5><ul>
<li>counting, windowing, and rolling averages are straightforward in Spark Streaming</li>
</ul>
<h5 id="ENRICHMENT-AND-ALERTING-2"><a href="#ENRICHMENT-AND-ALERTING-2" class="headerlink" title="ENRICHMENT AND ALERTING"></a>ENRICHMENT AND ALERTING</h5><ul>
<li>have performance throughput advantages if it requires lookup from external systems like HBase to execute the enrichment and/or alerting</li>
<li>major downside here is the latency, seconds level microbatching</li>
</ul>
<h5 id="LAMDBA-ARCHITECTURE-2"><a href="#LAMDBA-ARCHITECTURE-2" class="headerlink" title="LAMDBA ARCHITECTURE"></a>LAMDBA ARCHITECTURE</h5><ul>
<li>code reuse for Spark &amp; Spark Streaming</li>
</ul>

      

      
        
    </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/01/21/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
    <a href="/2019/12/16/Hadoop-Application-Architectures-Ch-6-Orchestration/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hadoop Application Architectures Ch.6 Orchestration</div>
    </a>
  
</nav>

  
</article>


</section>
        <aside id="sidebar">
  <nav class="menus">
  	<ul>
  		<li><a href="/"><i class="icon icon-home"></i></a></li>
  		
			<li><a href="/archives"><i class="icon icon-fenlei"></i></a></li>
  		
  		
			<li><a href="/tags"><i class="icon icon-tag"></i></a></li>
  		
  		
  	</ul>
  </nav>
  <a id="go-top" href="#"><i class="icon icon-up"></i></a>
</aside>

      </div>
      <footer id="footer">
  
	<div id="footer-info" class="inner">
	  &copy; 2020 Ansel Lin 
	  - Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	  - Theme <a href="https://github.com/hejianxian/hexo-theme-jane/" target="_blank">Jane</a>
	</div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tag</a>
  
    <a href="https://github.com/hejianxian" target="_blank" rel="noopener" class="mobile-nav-link">Github</a>
  
</nav>
    

<script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div>
</body>
</html>